{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drossel-Schwab Forest Fire Model\n",
    "\n",
    "Four experiments:\n",
    "1. **f/p Ratio Sweep** - Effect of fire-to-growth ratio\n",
    "2. **p Parameter Sweep** - Effect of growth probability\n",
    "3. **Grid Size Effects (RQ1)** - Scaling with system size\n",
    "4. **f Parameter Sweep** - Effect of fire/lightning probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import results\n",
    "from utils import (\n",
    "    create_experiment_dir, get_latest_experiment_dir,\n",
    "    run_parallel_simulations, save_summary,\n",
    "    load_experiment_data, load_summary_map,\n",
    "    plot_fire_size_distribution, plot_density_timeseries, plot_cluster_size_distribution,\n",
    ")\n",
    "from simulations.drosselschwab import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP1_NAME = \"suppression_test\"\n",
    "L, steps, runs_per_param = 512, 2000, 3\n",
    "p = 0.1\n",
    "f = 1e-4\n",
    "\n",
    "suppresions = [0, 1, 5, 10, 50, 100, 500, 1000, 5000]\n",
    "\n",
    "\n",
    "exp1_param_list = []\n",
    "param_idx = 0\n",
    "for sup in suppresions:\n",
    "        param_idx += 1\n",
    "        for run_idx in range(runs_per_param):\n",
    "            exp1_param_list.append({'L': L, 'p': p, 'f': f, 'steps': steps,\n",
    "                                    'param_id': param_idx, 'run_id': run_idx, 'suppress': sup})\n",
    "\n",
    "print(f\"Experiment 1: {len(exp1_param_list)} simulations, {param_idx} parameter sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run (uncomment to execute)\n",
    "exp1_outdir = create_experiment_dir(EXP1_NAME)\n",
    "exp1_results = run_parallel_simulations(exp1_param_list, exp1_outdir)\n",
    "save_summary(exp1_results, exp1_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze\n",
    "try:\n",
    "    exp1_dir = get_latest_experiment_dir(EXP1_NAME)\n",
    "    exp1_data = load_experiment_data(exp1_dir)\n",
    "    exp1_summary = load_summary_map(exp1_dir)\n",
    "    plot_fire_size_distribution(exp1_data, exp1_summary, \"Exp 1: Fire Size by f/p Ratio\",\n",
    "                                 results.path(\"exp1_fire_size_dist.png\"))\n",
    "    plot_density_timeseries(exp1_data, exp1_summary, \"Exp 1: Tree Density Over Time\",\n",
    "                            results.path(\"exp1_density_timeseries.png\"))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"No data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "\"\"\"\n",
    "Analyze the suppression paradox:\n",
    "- Group raw fire sizes by suppress value (from debug jsons)\n",
    "- Define megafire as absolute threshold or top quantile\n",
    "- Compute CCDFs, tail probs, bootstrapped CIs, KS tests vs baseline\n",
    "- Run logistic regression predicting whether a run had >=1 megafire\n",
    "- Plot CCDFs and megafire probability by suppress\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def load_experiment_fires(exp_dir):\n",
    "    # returns dict: (param_id, run_id) -> dict(params, fires_array)\n",
    "    dbg_files = sorted(glob.glob(os.path.join(exp_dir, \"debug_param*.json\")))\n",
    "    fires_files = sorted(glob.glob(os.path.join(exp_dir, \"fires_param*.csv\")))\n",
    "    # map by param/run from filename if possible\n",
    "    fires_map = {}\n",
    "    for f in fires_files:\n",
    "        base = os.path.basename(f)\n",
    "        # try to infer param/run\n",
    "        pid = None; rid = None\n",
    "        for tok in base.replace(\".\", \"_\").split(\"_\"):\n",
    "            if tok.startswith(\"param\"):\n",
    "                try: pid = int(tok.replace(\"param\", \"\"));\n",
    "                except: pass\n",
    "            if tok.startswith(\"run\"):\n",
    "                try: rid = int(tok.replace(\"run\", \"\"));\n",
    "                except: pass\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            if \"fire_size\" in df.columns:\n",
    "                arr = df[\"fire_size\"].to_numpy(dtype=float)\n",
    "            else:\n",
    "                # fallback first numeric column\n",
    "                arr = df.select_dtypes(include=[np.number]).iloc[:,0].to_numpy(dtype=float)\n",
    "        except Exception:\n",
    "            arr = np.array([], dtype=float)\n",
    "        fires_map[(pid, rid, base)] = {\"path\": f, \"fires\": arr}\n",
    "    runs = []\n",
    "    for dbg in dbg_files:\n",
    "        try:\n",
    "            info = json.load(open(dbg))\n",
    "            params = info.get(\"params\", {})\n",
    "            pid = params.get(\"param_id\")\n",
    "            rid = params.get(\"run_id\")\n",
    "            # try to find matching fires file\n",
    "            match = None\n",
    "            for (ppid, prid, base), v in fires_map.items():\n",
    "                if ppid == pid and (rid is None or prid == rid):\n",
    "                    match = v\n",
    "                    break\n",
    "            if match is None:\n",
    "                # fallback by substring\n",
    "                for (ppid, prid, base), v in fires_map.items():\n",
    "                    if pid is not None and f\"param{pid}\" in base:\n",
    "                        match = v; break\n",
    "            fires = match[\"fires\"] if match is not None else np.array([], dtype=float)\n",
    "            runs.append({\"params\": params, \"fires\": np.asarray(fires, dtype=float)})\n",
    "        except Exception:\n",
    "            continue\n",
    "    return runs\n",
    "\n",
    "def bootstrap_ci(data, statfunc=np.mean, nboot=2000, ci=0.95, rng=None):\n",
    "    rng = np.random.default_rng(rng)\n",
    "    n = len(data)\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    boots = []\n",
    "    for _ in range(nboot):\n",
    "        sample = rng.choice(data, size=n, replace=True)\n",
    "        boots.append(statfunc(sample))\n",
    "    boots = np.array(boots)\n",
    "    lower = np.percentile(boots, (1-ci)/2*100)\n",
    "    upper = np.percentile(boots, (1+ci)/2*100)\n",
    "    return statfunc(data), lower, upper\n",
    "\n",
    "def analyze_suppression_paradox(exp_dir, megafire_threshold=None, megafire_quantile=0.99):\n",
    "    runs = load_experiment_fires(exp_dir)\n",
    "    # group by suppress value\n",
    "    grouped = {}\n",
    "    per_run_summary = []\n",
    "    for r in runs:\n",
    "        params = r[\"params\"]\n",
    "        sup = params.get(\"suppress\", None)\n",
    "        fires = r[\"fires\"]\n",
    "        grouped.setdefault(sup, []).append(fires)\n",
    "        per_run_summary.append({\"suppress\": sup, \"fires\": fires})\n",
    "    # decide threshold\n",
    "    if megafire_threshold is None:\n",
    "        # global quantile across all fires\n",
    "        all_fires = np.concatenate([f for f in (r[\"fires\"] for r in runs) if len(f)>0]) if runs else np.array([])\n",
    "        if len(all_fires) == 0:\n",
    "            raise RuntimeError(\"No fire data found\")\n",
    "        megafire_threshold = np.quantile(all_fires[all_fires>0], megafire_quantile)  # ignore zeros if present\n",
    "\n",
    "    # compute statistics per suppress\n",
    "    stats_table = []\n",
    "    baseline_key = 0 if 0 in grouped else sorted(grouped.keys())[0]\n",
    "    baseline_all = np.concatenate(grouped[baseline_key]) if grouped.get(baseline_key) else np.array([])\n",
    "    for sup, list_runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        all_vec = np.concatenate(list_runs) if len(list_runs)>0 else np.array([])\n",
    "        # ignore non-positive if interpreting fire size >0\n",
    "        positive = all_vec[all_vec>0]\n",
    "        total_fires = len(all_vec)\n",
    "        megafire_count = np.sum(all_vec >= megafire_threshold)\n",
    "        megafire_prob = megafire_count / total_fires if total_fires>0 else np.nan\n",
    "        mean, mean_lo, mean_hi = bootstrap_ci(positive, np.mean)\n",
    "        median, med_lo, med_hi = bootstrap_ci(positive, np.median)\n",
    "        prob, prob_lo, prob_hi = bootstrap_ci((all_vec>=megafire_threshold).astype(int), np.mean)\n",
    "        # KS against baseline\n",
    "        if len(positive)>0 and len(baseline_all[baseline_all>0])>0:\n",
    "            ks_stat, ks_p = stats.ks_2samp(positive, baseline_all[baseline_all>0])\n",
    "        else:\n",
    "            ks_stat, ks_p = np.nan, np.nan\n",
    "        stats_table.append({\n",
    "            \"suppress\": sup,\n",
    "            \"n_runs\": len(list_runs),\n",
    "            \"total_fires\": int(total_fires),\n",
    "            \"megafire_prob\": prob,\n",
    "            \"megafire_prob_lo\": prob_lo,\n",
    "            \"megafire_prob_hi\": prob_hi,\n",
    "            \"mean_fire\": mean, \"mean_lo\": mean_lo, \"mean_hi\": mean_hi,\n",
    "            \"median_fire\": median, \"median_lo\": med_lo, \"median_hi\": med_hi,\n",
    "            \"ks_stat_vs_baseline\": ks_stat, \"ks_p_vs_baseline\": ks_p\n",
    "        })\n",
    "\n",
    "    df_stats = pd.DataFrame(stats_table)\n",
    "    print(\"Megafire threshold =\", megafire_threshold)\n",
    "    print(df_stats[[\"suppress\",\"n_runs\",\"total_fires\",\"megafire_prob\",\"mean_fire\",\"median_fire\",\"ks_p_vs_baseline\"]])\n",
    "\n",
    "    # run-level analysis: did a run have >=1 megafire?\n",
    "    run_rows = []\n",
    "    for r in per_run_summary:\n",
    "        fires = r[\"fires\"]\n",
    "        run_rows.append({\n",
    "            \"suppress\": r[\"suppress\"],\n",
    "            \"had_megafire\": int(np.any(fires >= megafire_threshold)),\n",
    "            \"num_megafires\": int(np.sum(fires >= megafire_threshold)),\n",
    "            \"total_fires\": int(len(fires))\n",
    "        })\n",
    "    df_runs = pd.DataFrame(run_rows).dropna(subset=[\"suppress\"])\n",
    "    # logistic regression (had_megafire ~ suppress)\n",
    "    # encode suppress numeric if possible\n",
    "    try:\n",
    "        df_runs[\"suppress_num\"] = df_runs[\"suppress\"].astype(float)\n",
    "        X = sm.add_constant(df_runs[[\"suppress_num\"]])\n",
    "        y = df_runs[\"had_megafire\"]\n",
    "        logit = sm.Logit(y, X).fit(disp=False)\n",
    "        print(\"Logistic regression summary (had_megafire ~ suppress):\")\n",
    "        print(logit.summary())\n",
    "    except Exception:\n",
    "        print(\"Skipping logistic regression (non-numeric suppress or insufficient data)\")\n",
    "\n",
    "    # Plots\n",
    "    plt.figure(figsize=(8,6))\n",
    "    # CCDF plot per suppress\n",
    "    for sup, list_runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        all_vec = np.concatenate(list_runs) if len(list_runs)>0 else np.array([])\n",
    "        pos = all_vec[all_vec>0]\n",
    "        if len(pos)==0:\n",
    "            continue\n",
    "        sorted_x = np.sort(pos)\n",
    "        ccdf = 1.0 - np.arange(1, len(sorted_x)+1)/len(sorted_x)\n",
    "        plt.loglog(sorted_x, ccdf, marker='.', linestyle='none', label=f\"suppress={sup}\")\n",
    "    plt.xlabel(\"Fire size\")\n",
    "    plt.ylabel(\"CCDF\")\n",
    "    plt.title(\"CCDF of fire sizes by suppress\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', ls='--', alpha=0.4)\n",
    "    plt.show()\n",
    "\n",
    "    # megafire probability bar with CI\n",
    "    plt.figure(figsize=(8,4))\n",
    "    xs = np.arange(len(df_stats))\n",
    "    plt.errorbar(xs, df_stats[\"megafire_prob\"], yerr=[df_stats[\"megafire_prob\"]-df_stats[\"megafire_prob_lo\"], df_stats[\"megafire_prob_hi\"]-df_stats[\"megafire_prob\"]], fmt='o', capsize=4)\n",
    "    plt.xticks(xs, [str(x) for x in df_stats[\"suppress\"]], rotation=45)\n",
    "    plt.xlabel(\"suppress\")\n",
    "    plt.ylabel(f\"P(fire >= {megafire_threshold:.3g})\")\n",
    "    plt.title(\"Megafire probability by suppress\")\n",
    "    plt.grid(True, ls='--', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # chi-square / contingency: counts of runs with/without megafire by suppress\n",
    "    contingency = []\n",
    "    labels = []\n",
    "    for sup, grp in df_runs.groupby(\"suppress\"):\n",
    "        n_with = grp[\"had_megafire\"].sum()\n",
    "        n_without = len(grp) - n_with\n",
    "        contingency.append([n_with, n_without])\n",
    "        labels.append(sup)\n",
    "    if len(contingency) >= 2:\n",
    "        chi2, pval, dof, expected = stats.chi2_contingency(np.array(contingency))\n",
    "        print(\"Chi-square across suppress groups (run-level had_megafire): p =\", pval)\n",
    "    else:\n",
    "        print(\"Not enough groups for chi-square test\")\n",
    "\n",
    "    return {\"df_stats\": df_stats, \"df_runs\": df_runs, \"megafire_threshold\": megafire_threshold}\n",
    "\n",
    "# Example usage:\n",
    "# res = analyze_suppression_paradox(exp_dir=\"experiments/suppression_test\", megafire_quantile=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run (uncomment to execute)\n",
    "L = 512\n",
    "\n",
    "plt.figure()\n",
    "results = []\n",
    "\n",
    "suppresions = [0,1, 5, 10, 50, 100, 1000]\n",
    "\n",
    "for sup in suppresions:\n",
    "\n",
    "    res = simulate_drosselschwab_record(L, p=0.1, f=0.001, steps=100, suppress=sup)\n",
    "\n",
    "    data = np.asarray(res[0])\n",
    "\n",
    "    all_size = len(data)\n",
    "    # remove non-positive values (log-scale requires >0)\n",
    "    data = data[data > 0]\n",
    "\n",
    "    if data.size == 0:\n",
    "        print(\"No positive data to plot.\")\n",
    "    else:\n",
    "        # choose number of bins (adjustable)\n",
    "        nbins = 50\n",
    "        # create log-spaced bins between min and max\n",
    "        bins = np.logspace(np.log10(data.min()), np.log10(data.max()), nbins)\n",
    "        counts, edges = np.histogram(data, bins=bins)\n",
    "        # geometric centers of bins\n",
    "        centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "        # filter zero-count bins for clearer log-log plotting\n",
    "        nonzero = counts > 0\n",
    "        plt.scatter(centers[nonzero], counts[nonzero]/len(data), s=20)  # dots\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Fire size')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Log-Log Fire Size Distribution (dots)')\n",
    "plt.grid(True, which='both', ls='--', alpha=0.5)\n",
    "plt.legend(suppresions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.array(res[0])), \"fires total\")\n",
    "print(np.sum(np.array(res[0])==0), \"fires supressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the simple histogram call with a log-log histogram plotted as dots\n",
    "import numpy as np\n",
    "\n",
    "data = np.asarray(res[0])\n",
    "# remove non-positive values (log-scale requires >0)\n",
    "data = data[data > 0]\n",
    "\n",
    "if data.size == 0:\n",
    "    print(\"No positive data to plot.\")\n",
    "else:\n",
    "    # choose number of bins (adjustable)\n",
    "    nbins = 50\n",
    "    # create log-spaced bins between min and max\n",
    "    bins = np.logspace(np.log10(data.min()), np.log10(data.max()), nbins)\n",
    "    counts, edges = np.histogram(data, bins=bins)\n",
    "    # geometric centers of bins\n",
    "    centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "    # filter zero-count bins for clearer log-log plotting\n",
    "    nonzero = counts > 0\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(centers[nonzero], counts[nonzero], s=20, c='k')  # dots\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Fire size')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Log-Log Fire Size Distribution (dots)')\n",
    "    plt.grid(True, which='both', ls='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 1: Sweep of f and p\n",
    "\n",
    "How does the ratio of fire probability to growth probability affect fire size distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP1_NAME = \"f_over_p\"\n",
    "L, steps, runs_per_param = 256, 2000, 3\n",
    "\n",
    "f_over_p_ratios = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "p_values = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "\n",
    "\n",
    "exp1_param_list = []\n",
    "param_idx = 0\n",
    "for p in p_values:\n",
    "    for ratio in f_over_p_ratios:\n",
    "        param_idx += 1\n",
    "        for run_idx in range(runs_per_param):\n",
    "            exp1_param_list.append({'L': L, 'p': p, 'f': p * ratio, 'steps': steps,\n",
    "                                    'param_id': param_idx, 'run_id': run_idx})\n",
    "\n",
    "print(f\"Experiment 1: {len(exp1_param_list)} simulations, {param_idx} parameter sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run (uncomment to execute)\n",
    "exp1_outdir = create_experiment_dir(EXP1_NAME)\n",
    "exp1_results = run_parallel_simulations(exp1_param_list, exp1_outdir)\n",
    "save_summary(exp1_results, exp1_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze\n",
    "try:\n",
    "    exp1_dir = get_latest_experiment_dir(EXP1_NAME)\n",
    "    exp1_data = load_experiment_data(exp1_dir)\n",
    "    exp1_summary = load_summary_map(exp1_dir)\n",
    "    plot_fire_size_distribution(exp1_data, exp1_summary, \"Exp 1: Fire Size by f/p Ratio\",\n",
    "                                 results.path(\"exp1_fire_size_dist.png\"))\n",
    "    plot_density_timeseries(exp1_data, exp1_summary, \"Exp 1: Tree Density Over Time\",\n",
    "                            results.path(\"exp1_density_timeseries.png\"))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"No data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 3: Grid Size Effects (RQ1)\n",
    "\n",
    "How does system size L affect scaling? Is log-log slope constant? How does cut-off change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP3_NAME = \"grid_size_rq1\"\n",
    "steps, runs_per_param = 2000, 3\n",
    "p_fixed, f_fixed = 0.01, 0.0001\n",
    "\n",
    "L_values = [32, 64, 128, 256, 512, 1028, 2056, 5012]\n",
    "\n",
    "exp3_param_list = []\n",
    "for param_idx, L in enumerate(L_values, 1):\n",
    "    for run_idx in range(runs_per_param):\n",
    "        exp3_param_list.append({'L': L, 'p': p_fixed, 'f': f_fixed, 'steps': steps,\n",
    "                                'param_id': param_idx, 'run_id': run_idx})\n",
    "\n",
    "print(f\"Experiment 3: {len(exp3_param_list)} simulations, L = {L_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run (uncomment to execute)\n",
    "exp3_outdir = create_experiment_dir(EXP3_NAME)\n",
    "exp3_results = run_parallel_simulations(exp3_param_list, exp3_outdir)\n",
    "save_summary(exp3_results, exp3_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze\n",
    "try:\n",
    "    exp3_dir = get_latest_experiment_dir(EXP3_NAME)\n",
    "    exp3_data = load_experiment_data(exp3_dir)\n",
    "    exp3_summary = load_summary_map(exp3_dir)\n",
    "    plot_fire_size_distribution(exp3_data, exp3_summary, \"Exp 3: Fire Size by Grid Size L\",\n",
    "                                 results.path(\"exp3_fire_size_dist.png\"))\n",
    "    plot_cluster_size_distribution(exp3_data, exp3_summary, \"Exp 3: Cluster Size by Grid Size L\",\n",
    "                                    results.path(\"exp3_cluster_size_dist.png\"))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"No data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 4: f Parameter Sweep\n",
    "\n",
    "How does fire/lightning probability alone affect system dynamics? (Complement to Exp 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP4_NAME = \"f_sweep\"\n",
    "L, steps, runs_per_param = 256, 5000, 3\n",
    "p_fixed = 0.05\n",
    "\n",
    "f_values = [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "\n",
    "exp4_param_list = []\n",
    "for param_idx, f in enumerate(f_values, 1):\n",
    "    for run_idx in range(runs_per_param):\n",
    "        exp4_param_list.append({'L': L, 'p': p_fixed, 'f': f, 'steps': steps,\n",
    "                                'param_id': param_idx, 'run_id': run_idx})\n",
    "\n",
    "print(f\"Experiment 4: {len(exp4_param_list)} simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run (uncomment to execute)\n",
    "exp4_outdir = create_experiment_dir(EXP4_NAME)\n",
    "exp4_results = run_parallel_simulations(exp4_param_list, exp4_outdir)\n",
    "save_summary(exp4_results, exp4_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze\n",
    "try:\n",
    "    exp4_dir = get_latest_experiment_dir(EXP4_NAME)\n",
    "    exp4_data = load_experiment_data(exp4_dir)\n",
    "    exp4_summary = load_summary_map(exp4_dir)\n",
    "    plot_fire_size_distribution(exp4_data, exp4_summary, \"Exp 4: Fire Size by f Value\",\n",
    "                                 results.path(\"exp4_fire_size_dist.png\"))\n",
    "    plot_density_timeseries(exp4_data, exp4_summary, \"Exp 4: Tree Density by f Value\",\n",
    "                            results.path(\"exp4_density_timeseries.png\"))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"No data: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
