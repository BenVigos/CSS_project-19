{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drossel-Schwab Forest Fire Model\n",
    "\n",
    "Four experiments:\n",
    "1. **f/p Ratio Sweep** - Effect of fire-to-growth ratio\n",
    "2. **p Parameter Sweep** - Effect of growth probability\n",
    "3. **Grid Size Effects (RQ1)** - Scaling with system size\n",
    "4. **f Parameter Sweep** - Effect of fire/lightning probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import results\n",
    "from utils import (\n",
    "    create_experiment_dir, get_latest_experiment_dir,\n",
    "    run_parallel_simulations, save_summary,\n",
    "    load_experiment_data, load_summary_map,\n",
    "    plot_fire_size_distribution, plot_density_timeseries, plot_cluster_size_distribution,\n",
    ")\n",
    "from simulations.drosselschwab import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP1_NAME = \"suppression_test\"\n",
    "L, steps, runs_per_param = 256, 2000, 3\n",
    "p = 0.01\n",
    "f = 1e-4\n",
    "\n",
    "suppresions = [0, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000]\n",
    "\n",
    "\n",
    "exp1_param_list = []\n",
    "param_idx = 0\n",
    "for sup in suppresions:\n",
    "        param_idx += 1\n",
    "        for run_idx in range(runs_per_param):\n",
    "            exp1_param_list.append({'L': L, 'p': p, 'f': f, 'steps': steps,\n",
    "                                    'param_id': param_idx, 'run_id': run_idx, 'suppress': sup})\n",
    "\n",
    "print(f\"Experiment 1: {len(exp1_param_list)} simulations, {param_idx} parameter sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run (uncomment to execute)\n",
    "exp1_outdir = create_experiment_dir(EXP1_NAME)\n",
    "exp1_results = run_parallel_simulations(exp1_param_list, exp1_outdir)\n",
    "save_summary(exp1_results, exp1_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze\n",
    "try:\n",
    "    exp1_dir = get_latest_experiment_dir(EXP1_NAME)\n",
    "    exp1_data = load_experiment_data(exp1_dir)\n",
    "    exp1_summary = load_summary_map(exp1_dir)\n",
    "    plot_fire_size_distribution(exp1_data, exp1_summary, \"Exp 1: Fire Size by f/p Ratio\",\n",
    "                                 results.path(\"exp1_fire_size_dist.png\"))\n",
    "    plot_density_timeseries(exp1_data, exp1_summary, \"Exp 1: Tree Density Over Time\",\n",
    "                            results.path(\"exp1_density_timeseries.png\"))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"No data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.utils import _make_label\n",
    "\n",
    "\n",
    "def plot_fire_size_distribution(runs_by_param: dict, summary_map: dict = None,\n",
    "                                 title: str = \"Fire Size Distribution\", save_path = None):\n",
    "    \"\"\"Plot fire size distribution (log-log).\"\"\"\n",
    "    plot_size_distribution(runs_by_param, 'fires_all', summary_map, title, 'Fire size', save_path)\n",
    "\n",
    "def plot_size_distribution(runs_by_param: dict, data_key: str = 'fires_all',\n",
    "                           summary_map: dict = None, title: str = \"Size Distribution\",\n",
    "                           xlabel: str = \"Size\", save_path= None):\n",
    "    \"\"\"Plot log-log size distribution. data_key is 'fires_all' or 'clusters_all'.\"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Collect all data for global bins\n",
    "    all_data = []\n",
    "    for runs in runs_by_param.values():\n",
    "        for r in runs:\n",
    "            all_data.extend(r[data_key])\n",
    "\n",
    "    if not all_data:\n",
    "        print(f\"No {data_key} recorded\")\n",
    "        return\n",
    "\n",
    "    all_data = np.array(all_data)\n",
    "    bins = np.logspace(np.log10(max(1, all_data.min())), np.log10(all_data.max()), num=25)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for pid in sorted(runs_by_param.keys()):\n",
    "        agg = np.concatenate([np.array(r[data_key]) for r in runs_by_param[pid] if r[data_key]])\n",
    "        if agg.size == 0:\n",
    "            continue\n",
    "\n",
    "        hist, edges = np.histogram(agg, bins=bins, density=True)\n",
    "        centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "        mask = hist > 0\n",
    "        plt.loglog(centers[mask]/256**2, hist[mask], 'o-', label=_make_label(pid, summary_map))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Probability density')\n",
    "    plt.legend(fontsize='small')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plot_fire_size_distribution(exp1_data, exp1_summary, \"Exp 1: Fire Size by f/p Ratio\",\n",
    "                                 results.path(\"exp1_fire_size_dist.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "\"\"\"\n",
    "Analyze the suppression paradox:\n",
    "- Group raw fire sizes by suppress value (from debug jsons)\n",
    "- Define megafire as absolute threshold or top quantile\n",
    "- Compute CCDFs, tail probs, bootstrapped CIs, KS tests vs baseline\n",
    "- Run logistic regression predicting whether a run had >=1 megafire\n",
    "- Plot CCDFs and megafire probability by suppress\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def load_experiment_fires(exp_dir):\n",
    "    # returns dict: (param_id, run_id) -> dict(params, fires_array)\n",
    "    dbg_files = sorted(glob.glob(os.path.join(exp_dir, \"debug_param*.json\")))\n",
    "    fires_files = sorted(glob.glob(os.path.join(exp_dir, \"fires_param*.csv\")))\n",
    "    # map by param/run from filename if possible\n",
    "    fires_map = {}\n",
    "    for f in fires_files:\n",
    "        base = os.path.basename(f)\n",
    "        # try to infer param/run\n",
    "        pid = None; rid = None\n",
    "        for tok in base.replace(\".\", \"_\").split(\"_\"):\n",
    "            if tok.startswith(\"param\"):\n",
    "                try: pid = int(tok.replace(\"param\", \"\"));\n",
    "                except: pass\n",
    "            if tok.startswith(\"run\"):\n",
    "                try: rid = int(tok.replace(\"run\", \"\"));\n",
    "                except: pass\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            if \"fire_size\" in df.columns:\n",
    "                arr = df[\"fire_size\"].to_numpy(dtype=float)\n",
    "            else:\n",
    "                # fallback first numeric column\n",
    "                arr = df.select_dtypes(include=[np.number]).iloc[:,0].to_numpy(dtype=float)\n",
    "        except Exception:\n",
    "            arr = np.array([], dtype=float)\n",
    "        fires_map[(pid, rid, base)] = {\"path\": f, \"fires\": arr}\n",
    "    runs = []\n",
    "    for dbg in dbg_files:\n",
    "        try:\n",
    "            info = json.load(open(dbg))\n",
    "            params = info.get(\"params\", {})\n",
    "            pid = params.get(\"param_id\")\n",
    "            rid = params.get(\"run_id\")\n",
    "            # try to find matching fires file\n",
    "            match = None\n",
    "            for (ppid, prid, base), v in fires_map.items():\n",
    "                if ppid == pid and (rid is None or prid == rid):\n",
    "                    match = v\n",
    "                    break\n",
    "            if match is None:\n",
    "                # fallback by substring\n",
    "                for (ppid, prid, base), v in fires_map.items():\n",
    "                    if pid is not None and f\"param{pid}\" in base:\n",
    "                        match = v; break\n",
    "            fires = match[\"fires\"] if match is not None else np.array([], dtype=float)\n",
    "            runs.append({\"params\": params, \"fires\": np.asarray(fires, dtype=float)})\n",
    "        except Exception:\n",
    "            continue\n",
    "    return runs\n",
    "\n",
    "def bootstrap_ci(data, statfunc=np.mean, nboot=2000, ci=0.95, rng=None):\n",
    "    rng = np.random.default_rng(rng)\n",
    "    n = len(data)\n",
    "    if n == 0:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    boots = []\n",
    "    for _ in range(nboot):\n",
    "        sample = rng.choice(data, size=n, replace=True)\n",
    "        boots.append(statfunc(sample))\n",
    "    boots = np.array(boots)\n",
    "    lower = np.percentile(boots, (1-ci)/2*100)\n",
    "    upper = np.percentile(boots, (1+ci)/2*100)\n",
    "    return statfunc(data), lower, upper\n",
    "\n",
    "def analyze_suppression_paradox(exp_dir, megafire_threshold=None, megafire_quantile=0.99):\n",
    "    runs = load_experiment_fires(exp_dir)\n",
    "    # group by suppress value\n",
    "    grouped = {}\n",
    "    per_run_summary = []\n",
    "    for r in runs:\n",
    "        params = r[\"params\"]\n",
    "        sup = params.get(\"suppress\", None)\n",
    "        fires = r[\"fires\"]\n",
    "        grouped.setdefault(sup, []).append(fires)\n",
    "        per_run_summary.append({\"suppress\": sup, \"fires\": fires})\n",
    "    # decide threshold\n",
    "    if megafire_threshold is None:\n",
    "        # global quantile across all fires\n",
    "        all_fires = np.concatenate([f for f in (r[\"fires\"] for r in runs) if len(f)>0]) if runs else np.array([])\n",
    "        if len(all_fires) == 0:\n",
    "            raise RuntimeError(\"No fire data found\")\n",
    "        megafire_threshold = np.quantile(all_fires[all_fires>0], megafire_quantile)  # ignore zeros if present\n",
    "\n",
    "    # compute statistics per suppress\n",
    "    stats_table = []\n",
    "    baseline_key = 0 if 0 in grouped else sorted(grouped.keys())[0]\n",
    "    baseline_all = np.concatenate(grouped[baseline_key]) if grouped.get(baseline_key) else np.array([])\n",
    "    for sup, list_runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        all_vec = np.concatenate(list_runs) if len(list_runs)>0 else np.array([])\n",
    "        # ignore non-positive if interpreting fire size >0\n",
    "        positive = all_vec[all_vec>0]\n",
    "        total_fires = len(all_vec)\n",
    "        megafire_count = np.sum(all_vec >= megafire_threshold)\n",
    "        megafire_prob = megafire_count / total_fires if total_fires>0 else np.nan\n",
    "        mean, mean_lo, mean_hi = bootstrap_ci(positive, np.mean)\n",
    "        median, med_lo, med_hi = bootstrap_ci(positive, np.median)\n",
    "        prob, prob_lo, prob_hi = bootstrap_ci((all_vec>=megafire_threshold).astype(int), np.mean)\n",
    "        # KS against baseline\n",
    "        if len(positive)>0 and len(baseline_all[baseline_all>0])>0:\n",
    "            ks_stat, ks_p = stats.ks_2samp(positive, baseline_all[baseline_all>0])\n",
    "        else:\n",
    "            ks_stat, ks_p = np.nan, np.nan\n",
    "        stats_table.append({\n",
    "            \"suppress\": sup,\n",
    "            \"n_runs\": len(list_runs),\n",
    "            \"total_fires\": int(total_fires),\n",
    "            \"megafire_prob\": prob,\n",
    "            \"megafire_prob_lo\": prob_lo,\n",
    "            \"megafire_prob_hi\": prob_hi,\n",
    "            \"mean_fire\": mean, \"mean_lo\": mean_lo, \"mean_hi\": mean_hi,\n",
    "            \"median_fire\": median, \"median_lo\": med_lo, \"median_hi\": med_hi,\n",
    "            \"ks_stat_vs_baseline\": ks_stat, \"ks_p_vs_baseline\": ks_p\n",
    "        })\n",
    "\n",
    "    df_stats = pd.DataFrame(stats_table)\n",
    "    print(\"Megafire threshold =\", megafire_threshold)\n",
    "    print(df_stats[[\"suppress\",\"n_runs\",\"total_fires\",\"megafire_prob\",\"mean_fire\",\"median_fire\",\"ks_p_vs_baseline\"]])\n",
    "\n",
    "    # run-level analysis: did a run have >=1 megafire?\n",
    "    run_rows = []\n",
    "    for r in per_run_summary:\n",
    "        fires = r[\"fires\"]\n",
    "        run_rows.append({\n",
    "            \"suppress\": r[\"suppress\"],\n",
    "            \"had_megafire\": int(np.any(fires >= megafire_threshold)),\n",
    "            \"num_megafires\": int(np.sum(fires >= megafire_threshold)),\n",
    "            \"total_fires\": int(len(fires))\n",
    "        })\n",
    "    df_runs = pd.DataFrame(run_rows).dropna(subset=[\"suppress\"])\n",
    "    # logistic regression (had_megafire ~ suppress)\n",
    "    # encode suppress numeric if possible\n",
    "    try:\n",
    "        df_runs[\"suppress_num\"] = df_runs[\"suppress\"].astype(float)\n",
    "        X = sm.add_constant(df_runs[[\"suppress_num\"]])\n",
    "        y = df_runs[\"had_megafire\"]\n",
    "        logit = sm.Logit(y, X).fit(disp=False)\n",
    "        print(\"Logistic regression summary (had_megafire ~ suppress):\")\n",
    "        print(logit.summary())\n",
    "    except Exception:\n",
    "        print(\"Skipping logistic regression (non-numeric suppress or insufficient data)\")\n",
    "\n",
    "    # Plots\n",
    "    plt.figure(figsize=(8,6))\n",
    "    # CCDF plot per suppress\n",
    "    for sup, list_runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        all_vec = np.concatenate(list_runs) if len(list_runs)>0 else np.array([])\n",
    "        pos = all_vec[all_vec>0]\n",
    "        if len(pos)==0:\n",
    "            continue\n",
    "        sorted_x = np.sort(pos)\n",
    "        ccdf = 1.0 - np.arange(1, len(sorted_x)+1)/len(sorted_x)\n",
    "        plt.loglog(sorted_x, ccdf, marker='.', linestyle='none', label=f\"suppress={sup}\")\n",
    "    plt.xlabel(\"Fire size\")\n",
    "    plt.ylabel(\"CCDF\")\n",
    "    plt.title(\"CCDF of fire sizes by suppress\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', ls='--', alpha=0.4)\n",
    "    plt.show()\n",
    "\n",
    "    # megafire probability bar with CI\n",
    "    plt.figure(figsize=(8,4))\n",
    "    xs = np.arange(len(df_stats))\n",
    "    plt.errorbar(xs, df_stats[\"megafire_prob\"], yerr=[df_stats[\"megafire_prob\"]-df_stats[\"megafire_prob_lo\"], df_stats[\"megafire_prob_hi\"]-df_stats[\"megafire_prob\"]], fmt='o', capsize=4)\n",
    "    plt.xticks(xs, [str(x) for x in df_stats[\"suppress\"]], rotation=45)\n",
    "    plt.xlabel(\"suppress\")\n",
    "    plt.ylabel(f\"P(fire >= {megafire_threshold:.3g})\")\n",
    "    plt.title(\"Megafire probability by suppress\")\n",
    "    plt.grid(True, ls='--', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # chi-square / contingency: counts of runs with/without megafire by suppress\n",
    "    contingency = []\n",
    "    labels = []\n",
    "    for sup, grp in df_runs.groupby(\"suppress\"):\n",
    "        n_with = grp[\"had_megafire\"].sum()\n",
    "        n_without = len(grp) - n_with\n",
    "        contingency.append([n_with, n_without])\n",
    "        labels.append(sup)\n",
    "    if len(contingency) >= 2:\n",
    "        chi2, pval, dof, expected = stats.chi2_contingency(np.array(contingency))\n",
    "        print(\"Chi-square across suppress groups (run-level had_megafire): p =\", pval)\n",
    "    else:\n",
    "        print(\"Not enough groups for chi-square test\")\n",
    "\n",
    "    return {\"df_stats\": df_stats, \"df_runs\": df_runs, \"megafire_threshold\": megafire_threshold}\n",
    "\n",
    "# Example usage:\n",
    "res = analyze_suppression_paradox(exp_dir=exp1_dir, megafire_quantile=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: suppression paradox diagnostics (log-log density, means/medians, maxima, megafire rates)\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIG --- edit these as you like ---\n",
    "EXP_DIR = get_latest_experiment_dir(\"suppression_test\")  # or set explicit path: Path(\"data/.../experiment_1\")\n",
    "NBINS = 30                # bins for log-histogram\n",
    "AREA_NORMALIZE = True      # when True x-axis is size normalized by area (L**2)\n",
    "INCLUDE_ZEROS_IN_DENOM = False  # for density normalization: if True divide by total events (including zeros)\n",
    "MEGAFIRE_THRESHOLD = None  # absolute threshold (None => use MEGAFIRE_FRACTION)\n",
    "MEGAFIRE_FRACTION = 0.01   # if MEGAFIRE_THRESHOLD is None, threshold = fraction * L**2\n",
    "SHOW_BOXPLOT = True\n",
    "VERBOSE = True\n",
    "# --- end CONFIG ---\n",
    "\n",
    "def discover_runs(exp_dir):\n",
    "    \"\"\"Return list of runs: dict with keys params (dict) and fires (np.array) and L (int).\"\"\"\n",
    "    ed = Path(exp_dir)\n",
    "    debug_files = sorted(ed.glob(\"debug_param*.json\"))\n",
    "    fire_files = sorted(ed.glob(\"fires_param*.csv\"))\n",
    "\n",
    "    # index fire files by tokens to match param/run\n",
    "    fire_index = {}\n",
    "    for f in fire_files:\n",
    "        name = f.name\n",
    "        # try to parse param and id tokens (filename patterns produced by worker)\n",
    "        pid = None; rid = None\n",
    "        toks = name.replace(\".\", \"_\").split(\"_\")\n",
    "        for t in toks:\n",
    "            if t.startswith(\"param\"):\n",
    "                try: pid = int(t.replace(\"param\", \"\"));\n",
    "                except: pass\n",
    "            if t.startswith(\"id\"):\n",
    "                # id token in your pattern is 'id{run}' before timestamp, so handle both 'id7' or 'id7' in tokens\n",
    "                try: rid = int(t.replace(\"id\", \"\"));\n",
    "                except: pass\n",
    "        fire_index.setdefault((pid, rid), []).append(f)\n",
    "\n",
    "    runs = []\n",
    "    for dbg in debug_files:\n",
    "        try:\n",
    "            info = json.load(open(dbg, 'r'))\n",
    "        except Exception:\n",
    "            if VERBOSE: print(\"failed to read\", dbg)\n",
    "            continue\n",
    "        params = info.get(\"params\", {})\n",
    "        pid = params.get(\"param_id\")\n",
    "        rid = params.get(\"run_id\")\n",
    "        # pick matching fire file (prefer exact pid,rid)\n",
    "        candidates = fire_index.get((pid, rid), []) + fire_index.get((pid, None), [])\n",
    "        fire_arr = np.array([], dtype=float)\n",
    "        if candidates:\n",
    "            # pick first candidate (should be unique)\n",
    "            try:\n",
    "                df = pd.read_csv(candidates[0])\n",
    "                if 'fire_size' in df.columns:\n",
    "                    fire_arr = df['fire_size'].to_numpy(dtype=float)\n",
    "                else:\n",
    "                    # fallback: first numeric column\n",
    "                    nums = df.select_dtypes(include=[np.number])\n",
    "                    if not nums.empty:\n",
    "                        fire_arr = nums.iloc[:,0].to_numpy(dtype=float)\n",
    "                    else:\n",
    "                        fire_arr = np.array([], dtype=float)\n",
    "            except Exception as e:\n",
    "                if VERBOSE: print(\"failed reading fires file\", candidates[0], e)\n",
    "                fire_arr = np.array([], dtype=float)\n",
    "        else:\n",
    "            # fallback: scan any fire file that contains \"param{pid}\" in name\n",
    "            fallback = None\n",
    "            if pid is not None:\n",
    "                for f in fire_files:\n",
    "                    if f\"param{pid}\" in f.name:\n",
    "                        fallback = f; break\n",
    "            if fallback:\n",
    "                try:\n",
    "                    df = pd.read_csv(fallback)\n",
    "                    if 'fire_size' in df.columns:\n",
    "                        fire_arr = df['fire_size'].to_numpy(dtype=float)\n",
    "                    else:\n",
    "                        nums = df.select_dtypes(include=[np.number])\n",
    "                        if not nums.empty:\n",
    "                            fire_arr = nums.iloc[:,0].to_numpy(dtype=float)\n",
    "                        else:\n",
    "                            fire_arr = np.array([], dtype=float)\n",
    "                except Exception as e:\n",
    "                    if VERBOSE: print(\"fallback read failed\", fallback, e)\n",
    "                    fire_arr = np.array([], dtype=float)\n",
    "\n",
    "        runs.append({'params': params, 'fires': np.asarray(fire_arr, dtype=float)})\n",
    "    return runs\n",
    "\n",
    "def group_by_suppress(runs):\n",
    "    \"\"\"Return dict: suppress_value -> list of np.arrays (fires for each run) and store L values seen.\"\"\"\n",
    "    by_sup = {}\n",
    "    Ls = []\n",
    "    for r in runs:\n",
    "        sup = r['params'].get('suppress', None)\n",
    "        L = r['params'].get('L', None)\n",
    "        if L is not None:\n",
    "            try: Ls.append(int(L))\n",
    "            except: pass\n",
    "        by_sup.setdefault(sup, []).append(r['fires'])\n",
    "    return by_sup, Ls\n",
    "\n",
    "def log_density_plot(grouped, area=None, area_norm=True, include_zeros_in_denom=False, nbins=40, ax=None):\n",
    "    \"\"\"Plot log-log density vs size (optionally normalized by area).\n",
    "\n",
    "    include_zeros_in_denom: if True divide counts by total events (including zeros);\n",
    "                           if False divide by positive-only events (so density integrates to 1 over >0).\n",
    "    area: if provided, divides x-axis (sizes) by this area for normalization (e.g. L**2)\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,6))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # pick global limits across groups (only positive sizes)\n",
    "    all_pos = []\n",
    "    for runs in grouped.values():\n",
    "        for arr in runs:\n",
    "            if arr is None:\n",
    "                continue\n",
    "            all_pos.extend(list(np.asarray(arr)[np.asarray(arr) > 0]))\n",
    "    if len(all_pos) == 0:\n",
    "        print(\"No positive fire sizes found.\")\n",
    "        return ax\n",
    "    all_pos = np.array(all_pos)\n",
    "    xmin = np.min(all_pos)\n",
    "    xmax = np.max(all_pos)\n",
    "    # protect against degenerate ranges\n",
    "    if xmin <= 0 or xmax <= 0 or xmin == xmax:\n",
    "        bins = np.logspace(np.log10(max(1, xmin)), np.log10(max(1, xmax if xmax>0 else xmin+1)), nbins)\n",
    "    else:\n",
    "        bins = np.logspace(np.log10(xmin), np.log10(xmax), nbins)\n",
    "\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        if not runs:\n",
    "            continue\n",
    "        all_f = np.concatenate([np.asarray(r) for r in runs]) if len(runs)>1 else np.asarray(runs[0])\n",
    "        positive = all_f[all_f > 0]\n",
    "        if positive.size == 0:\n",
    "            continue\n",
    "        counts, edges = np.histogram(positive, bins=bins)\n",
    "        widths = edges[1:] - edges[:-1]\n",
    "        if include_zeros_in_denom:\n",
    "            denom = len(all_f)  # including zeros\n",
    "        else:\n",
    "            denom = positive.size  # only positive events\n",
    "        denom = denom if denom > 0 else 1\n",
    "        density = counts / (denom * widths)   # density per size-unit\n",
    "        centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "        # mask zero-density bins to avoid plotting zeros on log-scale and connecting across them\n",
    "        mask = density > 0\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        x = centers[mask].astype(float)\n",
    "        y = density[mask].astype(float)\n",
    "        if area_norm and area is not None and area > 0:\n",
    "            x = x / float(area)\n",
    "        # plot markers only (no lines) to avoid vertical connectors across gaps\n",
    "        ax.loglog(x, y, marker='o', label=f\"suppress={sup}\")\n",
    "\n",
    "    ax.set_xlabel(\"Fire size (normalized by area if requested)\" if area_norm and area is not None else \"Fire size\")\n",
    "    ax.set_ylabel(\"Probability density (log-log)\")\n",
    "    ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "    ax.legend(fontsize='small')\n",
    "    return ax\n",
    "\n",
    "def mean_median_by_suppress(grouped, include_zeros=True):\n",
    "    \"\"\"Return DataFrame with columns: suppress, run_mean_mean, run_mean_std, run_median_mean, run_median_std, n_runs\"\"\"\n",
    "    rows = []\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        per_run_means = []\n",
    "        per_run_medians = []\n",
    "        for arr in runs:\n",
    "            if include_zeros:\n",
    "                if arr.size==0:\n",
    "                    per_run_means.append(np.nan)\n",
    "                    per_run_medians.append(np.nan)\n",
    "                else:\n",
    "                    per_run_means.append(np.mean(arr))\n",
    "                    per_run_medians.append(np.median(arr))\n",
    "            else:\n",
    "                pos = arr[arr>0]\n",
    "                if pos.size==0:\n",
    "                    per_run_means.append(np.nan)\n",
    "                    per_run_medians.append(np.nan)\n",
    "                else:\n",
    "                    per_run_means.append(np.mean(pos))\n",
    "                    per_run_medians.append(np.median(pos))\n",
    "        per_run_means = np.array(per_run_means, dtype=float)\n",
    "        per_run_medians = np.array(per_run_medians, dtype=float)\n",
    "        rows.append({\n",
    "            'suppress': sup,\n",
    "            'n_runs': int(np.sum(~np.isnan(per_run_means))),\n",
    "            'mean_of_runs_mean': np.nanmean(per_run_means),\n",
    "            'std_of_runs_mean': np.nanstd(per_run_means),\n",
    "            'mean_of_runs_median': np.nanmean(per_run_medians),\n",
    "            'std_of_runs_median': np.nanstd(per_run_medians),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def per_run_maxima_boxplot(grouped, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    labels = []\n",
    "    data = []\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        perrun_max = [np.nan if arr.size==0 else float(np.max(arr)) for arr in runs]\n",
    "        data.append([v for v in perrun_max if not np.isnan(v)])\n",
    "        labels.append(str(sup))\n",
    "    ax.boxplot(data, labels=labels, showfliers=True)\n",
    "    ax.set_xlabel(\"suppress\")\n",
    "    ax.set_ylabel(\"Per-run max fire size\")\n",
    "    ax.set_title(\"Per-run maximum fire size distribution by suppression\")\n",
    "    ax.grid(alpha=0.2)\n",
    "    return ax\n",
    "\n",
    "def megafire_stats(grouped, Ls, threshold=None, fraction=None):\n",
    "    \"\"\"Return DataFrame with columns suppress, per_fire_prob, per_fire_count, per_run_prob, n_runs.\n",
    "       If threshold is None, use fraction * L**2 (requires Ls non-empty).\"\"\"\n",
    "    rows = []\n",
    "    # compute representative L\n",
    "    L_rep = int(np.median(Ls)) if Ls else None\n",
    "    if threshold is None:\n",
    "        if fraction is None:\n",
    "            raise ValueError(\"Either threshold or fraction must be provided\")\n",
    "        if L_rep is None:\n",
    "            raise ValueError(\"No L information to compute absolute threshold from fraction\")\n",
    "        threshold = fraction * (L_rep**2)\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        all_f = np.concatenate(runs) if runs else np.array([], dtype=float)\n",
    "        total_fires = len(all_f)\n",
    "        if total_fires == 0:\n",
    "            per_fire_prob = np.nan\n",
    "        else:\n",
    "            per_fire_prob = np.sum(all_f >= threshold) / total_fires\n",
    "        # per-run: fraction of runs that had >=1 megafire\n",
    "        run_has = [int(np.any(arr >= threshold)) for arr in runs]\n",
    "        run_level_prob = np.mean(run_has) if len(run_has)>0 else np.nan\n",
    "        rows.append({'suppress': sup, 'per_fire_prob': per_fire_prob, 'per_run_prob': run_level_prob, 'n_runs': len(runs), 'threshold': threshold})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---------------------- perform analysis ----------------------\n",
    "runs = discover_runs(EXP_DIR)\n",
    "if VERBOSE:\n",
    "    print(f\"Discovered {len(runs)} runs in {EXP_DIR}\")\n",
    "\n",
    "grouped, Ls = group_by_suppress(runs)\n",
    "if VERBOSE:\n",
    "    print(\"Suppression keys found:\", sorted(grouped.keys(), key=lambda x: (float('inf') if x is None else x)))\n",
    "\n",
    "# choose threshold\n",
    "abs_threshold = MEGAFIRE_THRESHOLD\n",
    "if abs_threshold is None:\n",
    "    if MEGAFIRE_FRACTION is not None:\n",
    "        if len(Ls)==0:\n",
    "            raise RuntimeError(\"No L found in run params to compute fraction-based threshold.\")\n",
    "        L_rep = int(np.median(Ls))\n",
    "        abs_threshold = MEGAFIRE_FRACTION * (L_rep**2)\n",
    "    else:\n",
    "        raise RuntimeError(\"No megafire threshold/fraction provided\")\n",
    "\n",
    "# 1) log-log density plot (normalized by area optionally outside function)\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "# For x-axis normalization we'll compute area here and transform x ticks later\n",
    "area = (int(np.median(Ls))**2) if Ls else 1\n",
    "log_density_plot(grouped, area_norm=False, include_zeros_in_denom=INCLUDE_ZEROS_IN_DENOM, nbins=NBINS, ax=ax)\n",
    "if AREA_NORMALIZE:\n",
    "    ax.set_xlabel(\"Fire size (fraction of grid area)\")\n",
    "    # rescale x-axis ticks by dividing by area (we plotted raw sizes), update tick labels\n",
    "    xticks = ax.get_xticks()\n",
    "    ax.set_xticklabels([f\"{xt/area:.2e}\" if xt>0 else \"0\" for xt in xticks])\n",
    "plt.title(\"Log-log fire-size density by suppression (bins log-spaced)\")\n",
    "plt.show()\n",
    "\n",
    "# 2) Mean & median per suppression, with and without zeros\n",
    "df_incl = mean_median_by_suppress(grouped, include_zeros=True)\n",
    "df_excl = mean_median_by_suppress(grouped, include_zeros=False)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "# means\n",
    "# axes[0].errorbar(df_incl['suppress'].astype(str), df_incl['mean_of_runs_mean'], yerr=df_incl['std_of_runs_mean'], fmt='o-', label='include zeros')\n",
    "axes[0].errorbar(df_excl['suppress'].astype(str), df_excl['mean_of_runs_mean'], yerr=df_excl['std_of_runs_mean'], fmt='s--')\n",
    "axes[0].set_xlabel(\"suppression limit\"); axes[0].set_ylabel(\"Mean fire size (per-run average)\"); axes[0].set_title(\"Mean fire size by suppression limit\"); axes[0].grid(alpha=0.3)\n",
    "\n",
    "\n",
    "# medians\n",
    "# axes[1].errorbar(df_incl['suppress'].astype(str), df_incl['mean_of_runs_median'], yerr=df_incl['std_of_runs_median'], fmt='o-', label='include zeros')\n",
    "axes[1].errorbar(df_excl['suppress'].astype(str), df_excl['mean_of_runs_median'], yerr=df_excl['std_of_runs_median'], fmt='s--')\n",
    "axes[1].set_xlabel(\"suppression limit\"); axes[1].set_ylabel(\"Median fire size (per-run median)\"); axes[1].set_title(\"Median fire size by suppression limit\"); axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 3) per-run maxima boxplot (and print overall maxima)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "per_run_maxima_boxplot(grouped, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "overall_max = {sup: (np.max(np.concatenate(runs)) if len(runs)>0 and np.concatenate(runs).size>0 else np.nan) for sup, runs in grouped.items()}\n",
    "print(\"Overall max per suppress:\")\n",
    "for k,v in sorted(overall_max.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "    print(\"suppress\", k, \"max\", v)\n",
    "\n",
    "# 4) megafire percentages\n",
    "df_meg = megafire_stats(grouped, Ls, threshold=abs_threshold)\n",
    "print(\"\\nMegafire threshold (absolute):\", abs_threshold)\n",
    "print(df_meg[['suppress','per_fire_prob','per_run_prob','n_runs']])\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "axes[0].bar(df_meg['suppress'].astype(str), df_meg['per_fire_prob']*100)\n",
    "axes[0].set_ylabel(\"% of fires >= threshold\")\n",
    "axes[0].set_title(\"Per-fire megafire percentage (%) by suppress\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[1].bar(df_meg['suppress'].astype(str), df_meg['per_run_prob']*100)\n",
    "axes[1].set_ylabel(\"% of runs with >=1 megafire\")\n",
    "axes[1].set_title(\"Per-run megafire probability (%) by suppress\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
