{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drossel-Schwab Forest Fire Model\n",
    "\n",
    "Four experiments:\n",
    "1. **f/p Ratio Sweep** - Effect of fire-to-growth ratio\n",
    "2. **p Parameter Sweep** - Effect of growth probability\n",
    "3. **Grid Size Effects (RQ1)** - Scaling with system size\n",
    "4. **f Parameter Sweep** - Effect of fire/lightning probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import results\n",
    "from utils import (\n",
    "    create_experiment_dir, get_latest_experiment_dir,\n",
    "    run_parallel_simulations, save_summary,\n",
    "    load_experiment_data, load_summary_map,\n",
    "    plot_fire_size_distribution, plot_density_timeseries, plot_cluster_size_distribution,\n",
    ")\n",
    "from simulations.drosselschwab import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP1_NAME = \"suppression_test\"\n",
    "L, steps, runs_per_param = 256, 2000, 10\n",
    "p = 0.01\n",
    "f = 1e-4\n",
    "\n",
    "suppresions = [0, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000]\n",
    "\n",
    "\n",
    "exp1_param_list = []\n",
    "param_idx = 0\n",
    "for sup in suppresions:\n",
    "        param_idx += 1\n",
    "        for run_idx in range(runs_per_param):\n",
    "            exp1_param_list.append({'L': L, 'p': p, 'f': f, 'steps': steps,\n",
    "                                    'param_id': param_idx, 'run_id': run_idx, 'suppress': sup})\n",
    "\n",
    "print(f\"Experiment 1: {len(exp1_param_list)} simulations, {param_idx} parameter sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run (uncomment to execute)\n",
    "exp1_outdir = create_experiment_dir(EXP1_NAME)\n",
    "exp1_results = run_parallel_simulations(exp1_param_list, exp1_outdir)\n",
    "save_summary(exp1_results, exp1_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: suppression paradox diagnostics (log-log density, means/medians, maxima, megafire rates)\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIG --- edit these as you like ---\n",
    "EXP_DIR = get_latest_experiment_dir(\"suppression_test\")  # or set explicit path: Path(\"data/.../experiment_1\")\n",
    "NBINS = 30                # bins for log-histogram\n",
    "AREA_NORMALIZE = True      # when True x-axis is size normalized by area (L**2)\n",
    "INCLUDE_ZEROS_IN_DENOM = False  # for density normalization: if True divide by total events (including zeros)\n",
    "MEGAFIRE_THRESHOLD = None  # absolute threshold (None => use MEGAFIRE_FRACTION)\n",
    "MEGAFIRE_FRACTION = 0.01   # if MEGAFIRE_THRESHOLD is None, threshold = fraction * L**2\n",
    "SHOW_BOXPLOT = True\n",
    "VERBOSE = True\n",
    "# New option: show suppressed fires as percent (True) or absolute count (False)\n",
    "SUPPRESS_AS_PERCENT = True\n",
    "# --- end CONFIG ---\n",
    "\n",
    "def discover_runs(exp_dir):\n",
    "    \"\"\"Return list of runs: dict with keys params (dict) and fires (np.array) and L (int).\"\"\"\n",
    "    ed = Path(exp_dir)\n",
    "    debug_files = sorted(ed.glob(\"debug_param*.json\"))\n",
    "    fire_files = sorted(ed.glob(\"fires_param*.csv\"))\n",
    "\n",
    "    # index fire files by tokens to match param/run\n",
    "    fire_index = {}\n",
    "    for f in fire_files:\n",
    "        name = f.name\n",
    "        # try to parse param and id tokens (filename patterns produced by worker)\n",
    "        pid = None; rid = None\n",
    "        toks = name.replace(\".\", \"_\").split(\"_\")\n",
    "        for t in toks:\n",
    "            if t.startswith(\"param\"):\n",
    "                try: pid = int(t.replace(\"param\", \"\"));\n",
    "                except: pass\n",
    "            if t.startswith(\"id\"):\n",
    "                # id token in your pattern is 'id{run}' before timestamp, so handle both 'id7' or 'id7' in tokens\n",
    "                try: rid = int(t.replace(\"id\", \"\"));\n",
    "                except: pass\n",
    "        fire_index.setdefault((pid, rid), []).append(f)\n",
    "\n",
    "    runs = []\n",
    "    for dbg in debug_files:\n",
    "        try:\n",
    "            info = json.load(open(dbg, 'r'))\n",
    "        except Exception:\n",
    "            if VERBOSE: print(\"failed to read\", dbg)\n",
    "            continue\n",
    "        params = info.get(\"params\", {})\n",
    "        pid = params.get(\"param_id\")\n",
    "        rid = params.get(\"run_id\")\n",
    "        # pick matching fire file (prefer exact pid,rid)\n",
    "        candidates = fire_index.get((pid, rid), []) + fire_index.get((pid, None), [])\n",
    "        fire_arr = np.array([], dtype=float)\n",
    "        if candidates:\n",
    "            # pick first candidate (should be unique)\n",
    "            try:\n",
    "                df = pd.read_csv(candidates[0])\n",
    "                if 'fire_size' in df.columns:\n",
    "                    fire_arr = df['fire_size'].to_numpy(dtype=float)\n",
    "                else:\n",
    "                    # fallback: first numeric column\n",
    "                    nums = df.select_dtypes(include=[np.number])\n",
    "                    if not nums.empty:\n",
    "                        fire_arr = nums.iloc[:,0].to_numpy(dtype=float)\n",
    "                    else:\n",
    "                        fire_arr = np.array([], dtype=float)\n",
    "            except Exception as e:\n",
    "                if VERBOSE: print(\"failed reading fires file\", candidates[0], e)\n",
    "                fire_arr = np.array([], dtype=float)\n",
    "        else:\n",
    "            # fallback: scan any fire file that contains \"param{pid}\" in name\n",
    "            fallback = None\n",
    "            if pid is not None:\n",
    "                for f in fire_files:\n",
    "                    if f\"param{pid}\" in f.name:\n",
    "                        fallback = f; break\n",
    "            if fallback:\n",
    "                try:\n",
    "                    df = pd.read_csv(fallback)\n",
    "                    if 'fire_size' in df.columns:\n",
    "                        fire_arr = df['fire_size'].to_numpy(dtype=float)\n",
    "                    else:\n",
    "                        nums = df.select_dtypes(include=[np.number])\n",
    "                        if not nums.empty:\n",
    "                            fire_arr = nums.iloc[:,0].to_numpy(dtype=float)\n",
    "                        else:\n",
    "                            fire_arr = np.array([], dtype=float)\n",
    "                except Exception as e:\n",
    "                    if VERBOSE: print(\"fallback read failed\", fallback, e)\n",
    "                    fire_arr = np.array([], dtype=float)\n",
    "\n",
    "        runs.append({'params': params, 'fires': np.asarray(fire_arr, dtype=float)})\n",
    "    return runs\n",
    "\n",
    "def group_by_suppress(runs):\n",
    "    \"\"\"Return dict: suppress_value -> list of np.arrays (fires for each run) and store L values seen.\"\"\"\n",
    "    by_sup = {}\n",
    "    Ls = []\n",
    "    for r in runs:\n",
    "        sup = r['params'].get('suppress', None)\n",
    "        L = r['params'].get('L', None)\n",
    "        if L is not None:\n",
    "            try: Ls.append(int(L))\n",
    "            except: pass\n",
    "        by_sup.setdefault(sup, []).append(r['fires'])\n",
    "    return by_sup, Ls\n",
    "\n",
    "def log_density_plot(grouped, area=None, area_norm=True, include_zeros_in_denom=False, nbins=40, ax=None):\n",
    "    \"\"\"Plot log-log density vs size (optionally normalized by area).\n",
    "\n",
    "    include_zeros_in_denom: if True divide counts by total events (including zeros);\n",
    "                           if False divide by positive-only events (so density integrates to 1 over >0).\n",
    "    area: if provided, divides x-axis (sizes) by this area for normalization (e.g. L**2)\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,6))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # pick global limits across groups (only positive sizes)\n",
    "    all_pos = []\n",
    "    for runs in grouped.values():\n",
    "        for arr in runs:\n",
    "            if arr is None:\n",
    "                continue\n",
    "            all_pos.extend(list(np.asarray(arr)[np.asarray(arr) > 0]))\n",
    "    if len(all_pos) == 0:\n",
    "        print(\"No positive fire sizes found.\")\n",
    "        return ax\n",
    "    all_pos = np.array(all_pos)\n",
    "    xmin = np.min(all_pos)\n",
    "    xmax = np.max(all_pos)\n",
    "    # protect against degenerate ranges\n",
    "    if xmin <= 0 or xmax <= 0 or xmin == xmax:\n",
    "        bins = np.logspace(np.log10(max(1, xmin)), np.log10(max(1, xmax if xmax>0 else xmin+1)), nbins)\n",
    "    else:\n",
    "        bins = np.logspace(np.log10(xmin), np.log10(xmax), nbins)\n",
    "\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        if not runs:\n",
    "            continue\n",
    "        all_f = np.concatenate([np.asarray(r) for r in runs]) if len(runs)>1 else np.asarray(runs[0])\n",
    "        positive = all_f[all_f > 0]\n",
    "        if positive.size == 0:\n",
    "            continue\n",
    "        counts, edges = np.histogram(positive, bins=bins)\n",
    "        widths = edges[1:] - edges[:-1]\n",
    "        if include_zeros_in_denom:\n",
    "            denom = len(all_f)  # including zeros\n",
    "        else:\n",
    "            denom = positive.size  # only positive events\n",
    "        denom = denom if denom > 0 else 1\n",
    "        density = counts / (denom * widths)   # density per size-unit\n",
    "        centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "        # mask zero-density bins to avoid plotting zeros on log-scale and connecting across them\n",
    "        mask = density > 0\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        x = centers[mask].astype(float)\n",
    "        y = density[mask].astype(float)\n",
    "        if area_norm and area is not None and area > 0:\n",
    "            x = x / float(area)\n",
    "        # plot markers only (no lines) to avoid vertical connectors across gaps\n",
    "        ax.loglog(x, y, marker='o', label=f\"suppression lim ={sup}\")\n",
    "\n",
    "    ax.set_xlabel(\"Fire size (normalized by area if requested)\" if area_norm and area is not None else \"Fire size\")\n",
    "    ax.set_ylabel(\"Probability density (log-log)\")\n",
    "    ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "    ax.legend(fontsize='small')\n",
    "    return ax\n",
    "\n",
    "def mean_median_by_suppress(grouped, include_zeros=True):\n",
    "    \"\"\"Return DataFrame with columns: suppress, run_mean_mean, run_mean_std, run_median_mean, run_median_std, n_runs\"\"\"\n",
    "    rows = []\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        per_run_means = []\n",
    "        per_run_medians = []\n",
    "        for arr in runs:\n",
    "            if include_zeros:\n",
    "                if arr.size==0:\n",
    "                    per_run_means.append(np.nan)\n",
    "                    per_run_medians.append(np.nan)\n",
    "                else:\n",
    "                    per_run_means.append(np.mean(arr))\n",
    "                    per_run_medians.append(np.median(arr))\n",
    "            else:\n",
    "                pos = arr[arr>0]\n",
    "                if pos.size==0:\n",
    "                    per_run_means.append(np.nan)\n",
    "                    per_run_medians.append(np.nan)\n",
    "                else:\n",
    "                    per_run_means.append(np.mean(pos))\n",
    "                    per_run_medians.append(np.median(pos))\n",
    "        per_run_means = np.array(per_run_means, dtype=float)\n",
    "        per_run_medians = np.array(per_run_medians, dtype=float)\n",
    "        rows.append({\n",
    "            'suppress': sup,\n",
    "            'n_runs': int(np.sum(~np.isnan(per_run_means))),\n",
    "            'mean_of_runs_mean': np.nanmean(per_run_means),\n",
    "            'std_of_runs_mean': np.nanstd(per_run_means),\n",
    "            'mean_of_runs_median': np.nanmean(per_run_medians),\n",
    "            'std_of_runs_median': np.nanstd(per_run_medians),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def per_run_maxima_boxplot(grouped, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    labels = []\n",
    "    data = []\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        perrun_max = [np.nan if arr.size==0 else float(np.max(arr)) for arr in runs]\n",
    "        data.append([v for v in perrun_max if not np.isnan(v)])\n",
    "        labels.append(str(sup))\n",
    "    ax.boxplot(data, labels=labels, showfliers=True)\n",
    "    ax.set_xlabel(\"suppression limit\")\n",
    "    ax.set_ylabel(\"Per-run max fire size\")\n",
    "    ax.set_title(\"Per-run maximum fire size distribution by suppression\")\n",
    "    ax.grid(alpha=0.2)\n",
    "    return ax\n",
    "\n",
    "def megafire_stats(grouped, Ls, threshold=None, fraction=None):\n",
    "    \"\"\"Return DataFrame with columns suppress, per_fire_prob, per_fire_count, per_run_prob, n_runs.\n",
    "       If threshold is None, use fraction * L**2 (requires Ls non-empty).\"\"\"\n",
    "    rows = []\n",
    "    # compute representative L\n",
    "    L_rep = int(np.median(Ls)) if Ls else None\n",
    "    if threshold is None:\n",
    "        if fraction is None:\n",
    "            raise ValueError(\"Either threshold or fraction must be provided\")\n",
    "        if L_rep is None:\n",
    "            raise ValueError(\"No L information to compute absolute threshold from fraction\")\n",
    "        threshold = fraction * (L_rep**2)\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        all_f = np.concatenate(runs) if runs else np.array([], dtype=float)\n",
    "        total_fires = len(all_f)\n",
    "        if total_fires == 0:\n",
    "            per_fire_prob = np.nan\n",
    "        else:\n",
    "            per_fire_prob = np.sum(all_f >= threshold) / total_fires\n",
    "        # per-run: fraction of runs that had >=1 megafire\n",
    "        run_has = [int(np.any(arr >= threshold)) for arr in runs]\n",
    "        run_level_prob = np.mean(run_has) if len(run_has)>0 else np.nan\n",
    "        rows.append({'suppress': sup, 'per_fire_prob': per_fire_prob, 'per_run_prob': run_level_prob, 'n_runs': len(runs), 'threshold': threshold})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---------------------- perform analysis ----------------------\n",
    "runs = discover_runs(EXP_DIR)\n",
    "if VERBOSE:\n",
    "    print(f\"Discovered {len(runs)} runs in {EXP_DIR}\")\n",
    "\n",
    "grouped, Ls = group_by_suppress(runs)\n",
    "if VERBOSE:\n",
    "    print(\"Suppression keys found:\", sorted(grouped.keys(), key=lambda x: (float('inf') if x is None else x)))\n",
    "\n",
    "# choose threshold\n",
    "abs_threshold = MEGAFIRE_THRESHOLD\n",
    "if abs_threshold is None:\n",
    "    if MEGAFIRE_FRACTION is not None:\n",
    "        if len(Ls)==0:\n",
    "            raise RuntimeError(\"No L found in run params to compute fraction-based threshold.\")\n",
    "        L_rep = int(np.median(Ls))\n",
    "        abs_threshold = MEGAFIRE_FRACTION * (L_rep**2)\n",
    "    else:\n",
    "        raise RuntimeError(\"No megafire threshold/fraction provided\")\n",
    "\n",
    "# 1) log-log density plot (normalized by area optionally outside function)\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "# For x-axis normalization we'll compute area here and transform x ticks later\n",
    "area = (int(np.median(Ls))**2) if Ls else 1\n",
    "log_density_plot(grouped, area_norm=False, include_zeros_in_denom=INCLUDE_ZEROS_IN_DENOM, nbins=NBINS, ax=ax)\n",
    "if AREA_NORMALIZE:\n",
    "    ax.set_xlabel(\"Fire size (fraction of grid area)\")\n",
    "    # rescale x-axis ticks by dividing by area (we plotted raw sizes), update tick labels\n",
    "    xticks = ax.get_xticks()\n",
    "    ax.set_xticklabels([f\"{xt/area:.2e}\" if xt>0 else \"0\" for xt in xticks])\n",
    "plt.title(\"Log-log fire-size density by suppression limit\")\n",
    "plt.show()\n",
    "\n",
    "# 2) Mean & median per suppression, with and without zeros\n",
    "df_incl = mean_median_by_suppress(grouped, include_zeros=True)\n",
    "df_excl = mean_median_by_suppress(grouped, include_zeros=False)\n",
    "\n",
    "# Compute suppressed-fire stats (absolute counts and percent)\n",
    "def suppressed_stats(grouped):\n",
    "    rows = []\n",
    "    for sup, runs in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "        total = 0\n",
    "        suppressed = 0\n",
    "        for arr in runs:\n",
    "            total += int(arr.size)\n",
    "            # treat zeros as fully suppressed fires\n",
    "            suppressed += int(np.sum(arr == 0))\n",
    "        pct = (suppressed / total * 100.0) if total > 0 else np.nan\n",
    "        rows.append({'suppress': sup, 'suppressed_count': suppressed, 'total_fires': total, 'suppressed_pct': pct})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_supp = suppressed_stats(grouped)\n",
    "\n",
    "# --- NEW: bootstrap helper for run-level means ---\n",
    "def bootstrap_mean_ci(values, nboot=2000, ci=0.95, rng=None):\n",
    "    \"\"\"Bootstrap the mean of `values` (resample values with replacement) and return (mean, lo, hi).\n",
    "    Expects a 1D numpy array of per-run summary values (may contain NaN).\"\"\"\n",
    "    vals = np.asarray(values, dtype=float)\n",
    "    vals = vals[~np.isnan(vals)]\n",
    "    if vals.size == 0:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    rng = np.random.default_rng(rng)\n",
    "    boots = rng.choice(vals, size=(nboot, vals.size), replace=True)\n",
    "    boot_means = boots.mean(axis=1)\n",
    "    lo = np.percentile(boot_means, (1-ci)/2*100)\n",
    "    hi = np.percentile(boot_means, (1+ci)/2*100)\n",
    "    return (vals.mean(), lo, hi)\n",
    "\n",
    "# Prepare data for plotting\n",
    "sups_sorted = [s for s, _ in sorted(grouped.items(), key=lambda x: (float('inf') if x[0] is None else x[0]))]\n",
    "mean_points = []\n",
    "ci_lows = []\n",
    "ci_highs = []\n",
    "for sup in sups_sorted:\n",
    "    runs = grouped.get(sup, [])\n",
    "    # compute per-run mean excluding zeros\n",
    "    per_run_means = []\n",
    "    for arr in runs:\n",
    "        pos = arr[arr > 0]\n",
    "        if pos.size == 0:\n",
    "            per_run_means.append(np.nan)\n",
    "        else:\n",
    "            per_run_means.append(np.mean(pos))\n",
    "    mean, lo, hi = bootstrap_mean_ci(np.array(per_run_means), nboot=2000)\n",
    "    mean_points.append(mean)\n",
    "    ci_lows.append(lo)\n",
    "    ci_highs.append(hi)\n",
    "\n",
    "# 2-panel figure: left = bootstrapped mean with 95% CI, right = suppressed counts/percent\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "# Left panel: bootstrapped mean fire size (zeros excluded)\n",
    "x_labels = [str(s) for s in sups_sorted]\n",
    "x = np.arange(len(sups_sorted))\n",
    "means = np.array(mean_points, dtype=float)\n",
    "lo = np.array(ci_lows, dtype=float)\n",
    "hi = np.array(ci_highs, dtype=float)\n",
    "# construct asymmetric errorbars\n",
    "yerr_lower = means - lo\n",
    "yerr_upper = hi - means\n",
    "# replace NaN with zero-length errors to avoid plotting issues\n",
    "yerr_lower = np.where(np.isfinite(yerr_lower), yerr_lower, 0.0)\n",
    "yerr_upper = np.where(np.isfinite(yerr_upper), yerr_upper, 0.0)\n",
    "\n",
    "axes[0].errorbar(x, means, yerr=[yerr_lower, yerr_upper], fmt='o-', capsize=4)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(x_labels, rotation=45)\n",
    "axes[0].set_xlabel('suppression limit')\n",
    "axes[0].set_ylabel('Mean fire size (zeros excluded)')\n",
    "axes[0].set_title('Mean fire size by suppression (95% CI)')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Right panel: suppressed fires (absolute or percent)\n",
    "if SUPPRESS_AS_PERCENT:\n",
    "    y = df_supp['suppressed_pct']\n",
    "    ylabel = '% suppressed fires'\n",
    "    title = 'Percent of fires fully suppressed by suppression limit'\n",
    "else:\n",
    "    y = df_supp['suppressed_count']\n",
    "    ylabel = 'Number of suppressed fires'\n",
    "    title = 'Absolute number of fires fully suppressed by suppression limit'\n",
    "\n",
    "axes[1].bar(df_supp['suppress'].astype(str), y, color='tab:orange')\n",
    "axes[1].set_xlabel('suppression limit')\n",
    "axes[1].set_ylabel(ylabel)\n",
    "axes[1].set_title(title)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 3) per-run maxima boxplot (and print overall maxima)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "per_run_maxima_boxplot(grouped, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "overall_max = {sup: (np.max(np.concatenate(runs)) if len(runs)>0 and np.concatenate(runs).size>0 else np.nan) for sup, runs in grouped.items()}\n",
    "print(\"Overall max per suppress:\")\n",
    "for k,v in sorted(overall_max.items(), key=lambda x: (float('inf') if x[0] is None else x[0])):\n",
    "    print(\"suppress\", k, \"max\", v)\n",
    "\n",
    "# 4) megafire percentages\n",
    "df_meg = megafire_stats(grouped, Ls, threshold=abs_threshold)\n",
    "print(\"\\nMegafire threshold (absolute):\", abs_threshold)\n",
    "print(df_meg[['suppress','per_fire_prob','per_run_prob','n_runs']])\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "axes[0].bar(df_meg['suppress'].astype(str), df_meg['per_fire_prob']*100)\n",
    "axes[0].set_ylabel(\"% of fires >= threshold\")\n",
    "axes[0].set_title(\"Per-fire megafire percentage (%) by suppress\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[1].bar(df_meg['suppress'].astype(str), df_meg['per_run_prob']*100)\n",
    "axes[1].set_ylabel(\"% of runs with >=1 megafire\")\n",
    "axes[1].set_title(\"Per-run megafire probability (%) by suppress\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
